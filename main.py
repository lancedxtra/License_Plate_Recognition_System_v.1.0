import cv2
import numpy as np
import argparse
import time
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from PIL import Image, ImageDraw, ImageFont

# å¯¼å…¥åœè½¦åœºç®¡ç†æ¨¡å—
from parking_system import ParkingManager

# å¯¼å…¥ä¸‰ä¸ªæ¨¡å—
from license_plate_detection import LicensePlateDetector
from license_plate_preprocessor import LicensePlatePreprocessor
from license_plate_ocr_engine import get_license_plate_info
from camera_realtime import RealTimeLicensePlateDetector
try:
    from video_processor import VideoLicensePlateProcessor, create_video_processor_from_system
    VIDEO_PROCESSOR_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: è§†é¢‘å¤„ç†å™¨æ¨¡å—ä¸å¯ç”¨: {e}")
    VIDEO_PROCESSOR_AVAILABLE = False

try:
    from camera_manager import (
        list_all_cameras,
        select_camera_interactive,
        get_camera_name,
        get_camera_info,
        print_camera_info,
        find_best_camera,
        CameraManager
    )
    CAMERA_MANAGER_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨: {e}")
    print("æ‘„åƒå¤´æ£€æµ‹åŠŸèƒ½å°†å—é™")
    CAMERA_MANAGER_AVAILABLE = False

# ==========================================
# æ–°å¢ï¼šåœè½¦åœºäº¤äº’é€»è¾‘å‡½æ•°
# ==========================================
def handle_parking_interaction(parking_manager: ParkingManager, plate_text: str):
    """
    å¤„ç†åœè½¦åœºçš„äº¤äº’é€»è¾‘ï¼ˆå…¥åœº/å‡ºåœº/è·³è¿‡ï¼‰
    """
    if plate_text == "æœªçŸ¥" or not plate_text:
        return

    print("\n" + "*" * 40)
    print(f"ã€åœè½¦åœºç³»ç»Ÿã€‘æ£€æµ‹åˆ°è½¦ç‰Œ: {plate_text}")
    print(f"å½“å‰å‰©ä½™è½¦ä½: {parking_manager.get_available_spots()}")
    print("*" * 40)
    
    while True:
        choice = input(f"å¯¹è½¦è¾† {plate_text} è¿›è¡Œæ“ä½œ? (1:å…¥åœº, 2:å‡ºåœº, n:è·³è¿‡): ").strip().lower()
        
        if choice == '1': # å…¥åœº
            success, msg = parking_manager.entry(plate_text)
            print(f"æ“ä½œç»“æœ: {msg}")
            break
            
        elif choice == '2': # å‡ºåœº
            success, result = parking_manager.exit(plate_text)
            if success:
                print("\n=== ğŸ§¾ åœè½¦è´¦å• ===")
                print(f"è½¦ç‰Œå·ç : {result['plate_number']}")
                print(f"å…¥åœºæ—¶é—´: {result['entry_time']}")
                print(f"å‡ºåœºæ—¶é—´: {result['exit_time']}")
                print(f"åœè½¦æ—¶é•¿: {result['duration']}")
                print(f"åº”æ”¶è´¹ç”¨: {result['cost']} å…ƒ")
                print("====================")
            else:
                print(f"é”™è¯¯: {result}")
            break
            
        elif choice == 'n': # è·³è¿‡
            print("å·²è·³è¿‡åœè½¦åœºæ“ä½œ")
            break
        else:
            print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1, 2 æˆ– n")
    print("-" * 40 + "\n")

# ==========================================
# æ–°å¢ï¼šåœè½¦åœºæ‰‹åŠ¨ç®¡ç†èœå•
# ==========================================
def handle_parking_management_mode(parking_manager: ParkingManager):
    """
    æ‰‹åŠ¨ç®¡ç†åœè½¦åœºè®°å½•çš„å­èœå•
    """
    while True:
        print("\n" + "=" * 60)
        print("åœè½¦åœºè®°å½•ç®¡ç†")
        print("=" * 60)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_used = len(parking_manager.records)
        available = parking_manager.capacity - total_used
        print(f"å½“å‰çŠ¶æ€: å·²å ç”¨ {total_used} / å‰©ä½™ {available}")
        
        print("\nè¯·é€‰æ‹©åŠŸèƒ½:")
        print("  1. æŸ¥çœ‹æ‰€æœ‰åœ¨åœºè½¦è¾†")
        print("  2. æ‰‹åŠ¨ç™»è®°å…¥åœº")
        print("  3. æ‰‹åŠ¨ç»“ç®—å‡ºåœº")
        print("  4. æŸ¥è¯¢ç‰¹å®šè½¦è¾†çŠ¶æ€")
        print("  0. è¿”å›ä¸»èœå•")
        print("=" * 60)
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-4): ").strip()
        
        if choice == '0':
            print("è¿”å›ä¸»èœå•")
            break
            
        elif choice == '1':
            print("\n=== åœ¨åœºè½¦è¾†åˆ—è¡¨ ===")
            if not parking_manager.records:
                print("å½“å‰åœè½¦åœºä¸ºç©º")
            else:
                print(f"{'è½¦ç‰Œå·':<15} | {'å…¥åœºæ—¶é—´'}")
                print("-" * 40)
                for plate, entry_time in parking_manager.records.items():
                    time_str = entry_time.strftime("%Y-%m-%d %H:%M:%S")
                    print(f"{plate:<15} | {time_str}")
            input("\næŒ‰ Enter é”®ç»§ç»­...")
            
        elif choice == '2':
            plate = input("\nè¯·è¾“å…¥è¦å…¥åœºçš„è½¦ç‰Œå·: ").strip()
            if plate:
                success, msg = parking_manager.entry(plate)
                print(f"ç»“æœ: {msg}")
            else:
                print("è½¦ç‰Œå·ä¸èƒ½ä¸ºç©º")
            input("\næŒ‰ Enter é”®ç»§ç»­...")
            
        elif choice == '3':
            plate = input("\nè¯·è¾“å…¥è¦å‡ºåœºçš„è½¦ç‰Œå·: ").strip()
            if plate:
                success, result = parking_manager.exit(plate)
                if success:
                    print("\n=== ğŸ§¾ åœè½¦è´¦å• ===")
                    print(f"è½¦ç‰Œå·ç : {result['plate_number']}")
                    print(f"å…¥åœºæ—¶é—´: {result['entry_time']}")
                    print(f"å‡ºåœºæ—¶é—´: {result['exit_time']}")
                    print(f"åœè½¦æ—¶é•¿: {result['duration']}")
                    print(f"åº”æ”¶è´¹ç”¨: {result['cost']} å…ƒ")
                    print("====================")
                else:
                    print(f"é”™è¯¯: {result}")
            else:
                print("è½¦ç‰Œå·ä¸èƒ½ä¸ºç©º")
            input("\næŒ‰ Enter é”®ç»§ç»­...")
            
        elif choice == '4':
            plate = input("\nè¯·è¾“å…¥è¦æŸ¥è¯¢çš„è½¦ç‰Œå·: ").strip()
            if plate in parking_manager.records:
                entry_time = parking_manager.records[plate]
                print(f"\nè½¦è¾† {plate} ç›®å‰åœ¨åœºå†…")
                print(f"å…¥åœºæ—¶é—´: {entry_time.strftime('%Y-%m-%d %H:%M:%S')}")
                # è®¡ç®—å½“å‰é¢„ä¼°è´¹ç”¨
                import datetime
                duration = datetime.datetime.now() - entry_time
                hours = duration.total_seconds() / 3600
                cost = round(max(1, hours) * parking_manager.rate_per_hour, 2)
                print(f"å·²åœæ—¶é•¿: {str(duration).split('.')[0]}")
                print(f"å½“å‰é¢„ä¼°è´¹ç”¨: {cost} å…ƒ")
            else:
                print(f"\nè½¦è¾† {plate} ä¸åœ¨åœºå†…")
            input("\næŒ‰ Enter é”®ç»§ç»­...")
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")

class LicensePlateSystem:
    """
    è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ - æ•´åˆæ£€æµ‹ã€çŸ«æ­£ã€é¢„å¤„ç†å’Œè¯†åˆ«ï¼ˆå«é¢œè‰²æ£€æµ‹ï¼‰
    """
    
    def __init__(self, 
                 detection_model_path: str = 'yolov8s.pt',
                 detection_conf_threshold: float = 0.5,
                 use_preprocessing: bool = True):
        """
        åˆå§‹åŒ–è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ
        
        Args:
            detection_model_path: YOLOæ£€æµ‹æ¨¡å‹è·¯å¾„
            detection_conf_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            use_preprocessing: æ˜¯å¦ä½¿ç”¨é¢„å¤„ç†
        """
        print("=" * 60)
        print("åˆå§‹åŒ–è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ...")
        print("=" * 60)
        
        # åˆå§‹åŒ–ä¸‰ä¸ªæ¨¡å—
        print("1. åŠ è½½è½¦ç‰Œæ£€æµ‹å™¨...")
        self.detector = LicensePlateDetector(
            model_path=detection_model_path,
            conf_threshold=detection_conf_threshold
        )
        
        print("2. åŠ è½½è½¦ç‰Œé¢„å¤„ç†å™¨...")
        self.preprocessor = LicensePlatePreprocessor(
            target_size=(640, 480)
        )
        
        self.use_preprocessing = use_preprocessing
        
        print("âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"  é¢„å¤„ç†: {'å¯ç”¨' if use_preprocessing else 'ç¦ç”¨'}")
        print()
    
    def draw_chinese_text(self, img, text, position, text_color, text_size=20):
        """
        ä½¿ç”¨PILç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬ (å¢å¼ºç‰ˆï¼šè‡ªåŠ¨å¯»æ‰¾å­—ä½“)
        """
        if (isinstance(img, np.ndarray)):
            # OpenCVå›¾ç‰‡(BGR)è½¬æ¢ä¸ºPILå›¾ç‰‡(RGB)
            img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(img_pil)
            
            # --- å­—ä½“åŠ è½½é€»è¾‘ ---
            font = None
            # å­—ä½“æŸ¥æ‰¾ä¼˜å…ˆçº§åˆ—è¡¨
            font_paths = [
                "simhei.ttf",                 # 1. ä¼˜å…ˆæ‰¾å½“å‰ç›®å½•ä¸‹çš„ simhei.ttf
                "msyh.ttf",                   # 2. æ‰¾å½“å‰ç›®å½•ä¸‹çš„ å¾®è½¯é›…é»‘
                "font.ttf",                   # 3. æ‰¾å½“å‰ç›®å½•ä¸‹çš„ font.ttf (ä½ å¯ä»¥è‡ªå·±æ”¹å)
                "C:/Windows/Fonts/simhei.ttf",# 4. Windows ç³»ç»Ÿç»å¯¹è·¯å¾„
                "C:/Windows/Fonts/msyh.ttf",  # 5. Windows ç³»ç»Ÿç»å¯¹è·¯å¾„ (å¾®è½¯é›…é»‘)
                "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf" # 6. Linux å¸¸è§è·¯å¾„
            ]
            
            for path in font_paths:
                if os.path.exists(path):
                    try:
                        font = ImageFont.truetype(path, text_size, encoding="utf-8")
                        break
                    except Exception as e:
                        continue
            
            # å¦‚æœæ²¡æ‰¾åˆ°ä»»ä½•ä¸­æ–‡å­—ä½“
            if font is None:
                # åªæ‰“å°ä¸€æ¬¡è­¦å‘Šï¼Œé¿å…åˆ·å±
                if not hasattr(self, '_font_warning_shown'):
                    print("\n" + "!"*60)
                    print("ã€ä¸¥é‡è­¦å‘Šã€‘æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“æ–‡ä»¶ï¼ä¸­æ–‡å°†æ— æ³•æ˜¾ç¤ºã€‚")
                    print("è¯·å°† simhei.ttf æˆ– msyh.ttf å¤åˆ¶åˆ° main.py åŒçº§ç›®å½•ä¸‹ï¼")
                    print("!"*60 + "\n")
                    self._font_warning_shown = True
                font = ImageFont.load_default() # å›é€€åˆ°ä¸æ”¯æŒä¸­æ–‡çš„é»˜è®¤å­—ä½“
            # -------------------
            
            # ç»˜åˆ¶æ–‡æœ¬ (stroke_width=1 ç»™æ–‡å­—åŠ ä¸ªé»‘è¾¹ï¼Œé˜²æ­¢åœ¨æµ…è‰²èƒŒæ™¯çœ‹ä¸æ¸…)
            try:
                draw.text(position, text, font=font, fill=text_color, stroke_width=0)
            except:
                # æ—§ç‰ˆPillowå¯èƒ½ä¸æ”¯æŒstroke_width
                draw.text(position, text, font=font, fill=text_color)
            
            # è½¬æ¢å›OpenCVæ ¼å¼
            return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        return img

    def process_single_plate(self, original_image: np.ndarray, plate_info: Dict, output_dir: str, plate_index: int, save_results: bool = True) -> Dict:
        """å¤„ç†å•ä¸ªè½¦ç‰Œ (å·²ä¿®å¤ ocr_time æŠ¥é”™)"""
        import time # ç¡®ä¿å¯¼å…¥timeåº“

        # è·å–çŸ«æ­£åçš„è½¦ç‰Œå›¾åƒ
        rectified_image = plate_info['rectified']
        if rectified_image is None or rectified_image.size == 0: return None
        
        # ç›´æ¥ä½¿ç”¨çŸ«æ­£åçš„å›¾åƒ
        final_plate_image = rectified_image 
        
        # ä¿å­˜ç”¨äºOCRçš„ä¸´æ—¶å›¾ç‰‡
        temp_plate_path = None
        if save_results:
            temp_plate_path = f"{output_dir}/plate_{plate_index}_for_ocr.jpg"
            cv2.imwrite(temp_plate_path, final_plate_image)
        
        ocr_input_path = temp_plate_path if temp_plate_path else f"temp_plate_{plate_index}.jpg"
        if not temp_plate_path: 
            cv2.imwrite(ocr_input_path, final_plate_image)
        
        # === ä¿®å¤ç‚¹ï¼šæ·»åŠ è®¡æ—¶é€»è¾‘ ===
        ocr_start_time = time.time()
        
        # è°ƒç”¨OCRå¼•æ“
        ocr_result = get_license_plate_info(ocr_input_path)
        
        # è®¡ç®—è€—æ—¶
        ocr_time = time.time() - ocr_start_time
        # ==========================
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if not temp_plate_path: 
            try: os.remove(ocr_input_path)
            except: pass
        
        # è§£æç»“æœ
        plate_text, ocr_confidence, plate_type = ("æœªçŸ¥", 0.0, "æœªçŸ¥")
        if ocr_result: 
            plate_text, ocr_confidence, plate_type = ocr_result
        
        # åœ¨åŸå›¾ä¸Šæ ‡æ³¨
        annotated_image = self._annotate_plate(
            original_image.copy(), 
            plate_info['bbox'], 
            plate_text, 
            plate_info['confidence'], 
            ocr_confidence, 
            plate_type
        )
        
        # ç»“æœæ‰“åŒ…
        result = {
            'plate_id': plate_index, 
            'detection_confidence': float(plate_info['confidence']),
            'bbox': plate_info['bbox'], 
            'plate_text': plate_text,
            'ocr_confidence': float(ocr_confidence), 
            'plate_type': plate_type,
            'rectified_image': rectified_image, 
            'preprocessed_image': final_plate_image, 
            'annotated_image': annotated_image,
            'ocr_time': ocr_time, # === ä¿®å¤ç‚¹ï¼šå°†æ—¶é—´åŠ å…¥ç»“æœå­—å…¸ ===
        }
        
        if save_results: 
            self._save_single_result(result, output_dir, plate_index)
            
        return result
    
    def process_image(self, image_path: str, 
                     save_results: bool = True,
                     output_dir: str = "results") -> List[Dict]:
        """
        å¤„ç†å•å¼ å›¾ç‰‡ï¼Œè¿”å›æ‰€æœ‰è½¦ç‰Œä¿¡æ¯
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            è½¦ç‰Œä¿¡æ¯åˆ—è¡¨
        """
        print(f"å¤„ç†å›¾ç‰‡: {image_path}")
        print("-" * 60)
        
        # è¯»å–åŸå§‹å›¾ç‰‡
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–å›¾ç‰‡ {image_path}")
            return []
        
        # 1. æ£€æµ‹å¹¶çŸ«æ­£è½¦ç‰Œ
        print("æ­¥éª¤1: æ£€æµ‹å¹¶çŸ«æ­£è½¦ç‰Œ...")
        start_time = time.time()
        
        plates_info = self.detector.detect_all_and_rectify(image_path)
        
        if not plates_info:
            print("æœªæ£€æµ‹åˆ°è½¦ç‰Œ")
            return []
        
        detection_time = time.time() - start_time
        print(f"âœ“ æ£€æµ‹åˆ° {len(plates_info)} ä¸ªè½¦ç‰Œ (è€—æ—¶: {detection_time:.2f}s)")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if save_results:
            Path(output_dir).mkdir(exist_ok=True)
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„è½¦ç‰Œ
        all_results = []
        
        for i, plate_info in enumerate(plates_info):
            result = self.process_single_plate(
                original_image=original_image,
                plate_info=plate_info,
                output_dir=output_dir,
                plate_index=i+1,
                save_results=save_results
            )
            
            if result:
                result['detection_time'] = float(detection_time)
                result['total_time'] = float(detection_time + result['ocr_time'])
                all_results.append(result)
        
        # 8. ä¿å­˜åŒ…å«æ‰€æœ‰è½¦ç‰Œçš„åŸå›¾
        if save_results and all_results:
            # ä½¿ç”¨æœ€åä¸€ä¸ªè½¦ç‰Œçš„æ ‡æ³¨å›¾åƒ
            final_annotated = all_results[-1]['annotated_image']
            
            final_path = f"{output_dir}/final_annotated.jpg"
            cv2.imwrite(final_path, final_annotated)
            print(f"\nâœ“ æœ€ç»ˆæ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜: {final_path}")
        
        # 9. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self._cleanup_temp_files()
        
        # 10. æ‰“å°æ±‡æ€»ç»“æœ
        self._print_summary(all_results)
        
        # 11. ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´ç»“æœ
        if save_results:
            self._save_json_results(all_results, output_dir)
        
        return all_results
    
    # ... (LicensePlateSystemçš„å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜) ...
    def _annotate_plate(self, image: np.ndarray, bbox: Tuple, plate_text: str, det_conf: float, ocr_conf: float, plate_type: str) -> np.ndarray:
        """å›¾ç‰‡æ¨¡å¼çš„æ ‡æ³¨ (ä¿®å¤ä¸­æ–‡ä¹±ç )"""
        x1, y1, x2, y2 = bbox
        
        # ç¡®å®šé¢œè‰²
        if plate_text != "æœªçŸ¥":
            color_map = {'è“ç‰Œ': (255,0,0), 'é»„ç‰Œ': (0,255,255), 'æ–°èƒ½æºç»¿ç‰Œ': (0,255,0)}
            color = color_map.get(plate_type, (0, 255, 0))
        else:
            color = (0, 0, 255) # çº¢è‰²
            
        # 1. ç»˜åˆ¶çŸ©å½¢æ¡†
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)
        
        # 2. å‡†å¤‡å¤šè¡Œæ–‡æœ¬
        lines = [
            f"è½¦ç‰Œ: {plate_text}",
            f"ç±»å‹: {plate_type}",
            f"ç½®ä¿¡åº¦: {ocr_conf:.2f}"
        ]
        
        # 3. ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
        line_height = 25
        text_area_height = len(lines) * line_height + 10
        text_area_width = 220 # ä¼°ç®—å®½åº¦
        
        # ç¡®å®šèƒŒæ™¯ä½ç½®ï¼ˆä¼˜å…ˆåœ¨ä¸Šæ–¹ï¼‰
        bg_y1 = max(0, y1 - text_area_height)
        bg_y2 = y1
        if bg_y1 == 0: # ä¸Šæ–¹ç©ºé—´ä¸è¶³ï¼Œç”»åœ¨ä¸‹æ–¹
            bg_y1 = y2
            bg_y2 = y2 + text_area_height
            
        # ç”»åŠé€æ˜èƒŒæ™¯
        overlay = image.copy()
        cv2.rectangle(overlay, (x1, bg_y1), (x1 + text_area_width, bg_y2), (0, 0, 0), -1)
        image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)
        
        # 4. å¾ªç¯ç»˜åˆ¶æ¯ä¸€è¡Œä¸­æ–‡
        y_offset = bg_y1 + 5
        for line in lines:
            # ç»Ÿä¸€ä½¿ç”¨ç™½è‰²æ–‡å­—
            image = self.draw_chinese_text(image, line, (x1 + 5, y_offset), (255, 255, 255), 20)
            y_offset += line_height
            
        return image
    
    def _save_comparison(self, before: np.ndarray, after: np.ndarray, 
                        output_dir: str, name: str):
        if before is None or after is None: return
        h1, w1 = before.shape[:2]
        h2, w2 = after.shape[:2]
        max_height = max(h1, h2)
        if h1 != max_height:
            scale1 = max_height / h1
            new_w1 = int(w1 * scale1)
            resized_before = cv2.resize(before, (new_w1, max_height))
        else:
            resized_before = before
            new_w1 = w1
        if h2 != max_height:
            scale2 = max_height / h2
            new_w2 = int(w2 * scale2)
            resized_after = cv2.resize(after, (new_w2, max_height))
        else:
            resized_after = after
            new_w2 = w2
        combined = np.hstack((resized_before, resized_after))
        cv2.putText(combined, "å¤„ç†å‰", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(combined, "å¤„ç†å", (new_w1 + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        save_path = f"{output_dir}/{name}_comparison.jpg"
        cv2.imwrite(save_path, combined)
    
    def _save_single_result(self, result: Dict, output_dir: str, plate_id: int):
        base_path = f"{output_dir}/plate_{plate_id}"
        if result['rectified_image'] is not None:
            cv2.imwrite(f"{base_path}_rectified.jpg", result['rectified_image'])
        if result['preprocessed_image'] is not None:
            cv2.imwrite(f"{base_path}_preprocessed.jpg", result['preprocessed_image'])
        if result['annotated_image'] is not None:
            cv2.imwrite(f"{base_path}_annotated.jpg", result['annotated_image'])
        with open(f"{base_path}_info.txt", "w", encoding="utf-8") as f:
            f.write("=" * 60 + "\n")
            f.write(f"è½¦ç‰Œ {plate_id} è¯†åˆ«ç»“æœ\n")
            f.write("=" * 60 + "\n\n")
            f.write("ã€åŸºæœ¬ä¿¡æ¯ã€‘\n")
            f.write(f"è½¦ç‰Œå·ç : {result['plate_text']}\n")
            f.write(f"è½¦ç‰Œç±»å‹: {result['plate_type']}\n")
            f.write(f"æ£€æµ‹ç½®ä¿¡åº¦: {result['detection_confidence']:.4f}\n")
            f.write(f"OCRç½®ä¿¡åº¦: {result['ocr_confidence']:.4f}\n")
            f.write(f"ä½ç½®åæ ‡: {result['bbox']}\n\n")
            f.write("ã€æ—¶é—´ç»Ÿè®¡ã€‘\n")
            if 'detection_time' in result:
                f.write(f"æ£€æµ‹è€—æ—¶: {result['detection_time']:.4f}s\n")
            f.write(f"è¯†åˆ«è€—æ—¶: {result['ocr_time']:.4f}s\n")
            if 'total_time' in result:
                f.write(f"æ€»è€—æ—¶: {result['total_time']:.4f}s\n\n")
    
    def _cleanup_temp_files(self):
        import glob
        temp_files = glob.glob("temp_plate_*.jpg") + glob.glob("temp_frame_*.jpg")
        for temp_file in temp_files:
            try: os.remove(temp_file)
            except: pass
    
    def _save_json_results(self, results: List[Dict], output_dir: str):
        serializable_results = []
        for result in results:
            serializable_result = {
                'plate_id': result['plate_id'],
                'plate_text': result['plate_text'],
                'plate_type': result['plate_type'],
                'detection_confidence': result['detection_confidence'],
                'ocr_confidence': result['ocr_confidence'],
                'bbox': result['bbox'],
            }
            if 'detection_time' in result: serializable_result['detection_time'] = result['detection_time']
            if 'ocr_time' in result: serializable_result['ocr_time'] = result['ocr_time']
            if 'total_time' in result: serializable_result['total_time'] = result['total_time']
            serializable_results.append(serializable_result)
        json_path = f"{output_dir}/results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        print(f"âœ“ JSONç»“æœå·²ä¿å­˜: {json_path}")
    
    def _print_summary(self, results: List[Dict]):
        if not results: return
        print("\n" + "=" * 60)
        print("è½¦ç‰Œè¯†åˆ«æ±‡æ€»ç»“æœ")
        print("=" * 60)
        total_detected = len(results)
        total_recognized = sum(1 for r in results if r['plate_text'] != "æœªçŸ¥")
        print(f"æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°: {total_detected}")
        print(f"æˆåŠŸè¯†åˆ«è½¦ç‰Œæ•°: {total_recognized}")
        print(f"è¯†åˆ«æˆåŠŸç‡: {total_recognized/total_detected*100:.1f}%")
        color_distribution = {}
        for result in results:
            color = result['plate_type']
            if color not in color_distribution:
                color_distribution[color] = 0
            color_distribution[color] += 1
        print("\nè½¦ç‰Œé¢œè‰²åˆ†å¸ƒ:")
        for color, count in color_distribution.items():
            percentage = count / total_detected * 100
            print(f"  {color}: {count}ä¸ª ({percentage:.1f}%)")
        print("\nå„è½¦ç‰Œè¯¦ç»†ç»“æœ:")
        print("-" * 60)
        for result in results:
            status = "âœ“" if result['plate_text'] != "æœªçŸ¥" else "âœ—"
            print(f"{status} è½¦ç‰Œ {result['plate_id']}:")
            print(f"  å·ç : {result['plate_text']}")
            print(f"  ç±»å‹: {result['plate_type']}")
            print(f"  æ£€æµ‹ç½®ä¿¡åº¦: {result['detection_confidence']:.4f}")
            print(f"  OCRç½®ä¿¡åº¦: {result['ocr_confidence']:.4f}")
            print()
        if 'total_time' in results[0]:
            total_time = sum(r['total_time'] for r in results)
            avg_time_per_plate = total_time / total_detected if total_detected > 0 else 0
            print(f"æ—¶é—´ç»Ÿè®¡:")
            print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.4f}s")
            print(f"  å¹³å‡æ¯ä¸ªè½¦ç‰Œ: {avg_time_per_plate:.4f}s")
        print("=" * 60)
        
    # æ·»åŠ æ‘„åƒå¤´æ£€æµ‹éœ€è¦çš„è¾…åŠ©æ–¹æ³•ï¼ˆå› ä¸ºæˆ‘ä»¬ä¸‹é¢è¦åœ¨main.pyé‡Œç›´æ¥è°ƒç”¨ï¼‰
    def _process_camera_detection(self, frame, plate_info, index=1):
        """å¤„ç†æ‘„åƒå¤´æ£€æµ‹åˆ°çš„å•ä¸ªè½¦ç‰Œ"""
        import time
        rectified_image = plate_info['rectified']
        if rectified_image is None or rectified_image.size == 0: return {}
        
        # OCR
        temp_path = f"temp_cam_plate_{index}.jpg"
        cv2.imwrite(temp_path, rectified_image)
        
        ocr_start = time.time()
        ocr_result = get_license_plate_info(temp_path)
        ocr_time = time.time() - ocr_start
        
        try: os.remove(temp_path)
        except: pass
        
        plate_text, ocr_conf, plate_type = ("æœªçŸ¥", 0.0, "æœªçŸ¥")
        if ocr_result:
            plate_text, ocr_conf, plate_type = ocr_result
            
        return {
            'plate_text': plate_text,
            'ocr_confidence': ocr_conf,
            'plate_type': plate_type,
            'bbox': plate_info['bbox'],
            'ocr_time': ocr_time
        }

    def _annotate_camera_frame(self, frame, result):
        """æ ‡æ³¨æ‘„åƒå¤´å¸§"""
        if not result: return frame
        return self._annotate_plate(
            frame, 
            result['bbox'], 
            result['plate_text'], 
            0.0, 
            result['ocr_confidence'], 
            result['plate_type']
        )


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿï¼ˆæ”¯æŒæ‘„åƒå¤´å®æ—¶æ£€æµ‹ï¼‰")
    
    # åˆå§‹åŒ–åœè½¦åœºç®¡ç†å™¨
    parking_manager = ParkingManager()
    
    # è¾“å…¥æºé€‰æ‹©
    input_group = parser.add_mutually_exclusive_group()
    input_group.add_argument("--image", type=str, help="å¤„ç†å•å¼ å›¾ç‰‡")
    input_group.add_argument("--video", type=str, help="å¤„ç†è§†é¢‘æ–‡ä»¶")
    input_group.add_argument("--camera", action="store_true", help="å¯åŠ¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
    input_group.add_argument("--batch", type=str, help="æ‰¹é‡å¤„ç†å›¾ç‰‡ç›®å½•")
    
    # æ‘„åƒå¤´é€‰æ‹©
    parser.add_argument("--list-cameras", action="store_true",
                       help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ‘„åƒå¤´")
    parser.add_argument("--interactive", action="store_true",
                       help="äº¤äº’å¼é€‰æ‹©æ‘„åƒå¤´")
    parser.add_argument("--camera-info", type=int, 
                       help="æ˜¾ç¤ºæ‘„åƒå¤´è¯¦ç»†ä¿¡æ¯")
    parser.add_argument("--test-camera", type=int,
                       help="æµ‹è¯•æŒ‡å®šæ‘„åƒå¤´")
    parser.add_argument("--find-best-camera", action="store_true",
                       help="å¯»æ‰¾æœ€ä½³æ‘„åƒå¤´")
    
    # è§†é¢‘å‚æ•°
    parser.add_argument("--video-start", type=float, default=0, 
                       help="è§†é¢‘å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--video-duration", type=float, default=0, 
                       help="è§†é¢‘å¤„ç†æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºæ•´ä¸ªè§†é¢‘")
    parser.add_argument("--video-output-fps", type=float, default=0, 
                       help="è¾“å‡ºè§†é¢‘å¸§ç‡ï¼Œ0è¡¨ç¤ºä¸åŸè§†é¢‘ç›¸åŒ")
    parser.add_argument("--max-frames", type=int, default=0, 
                       help="æœ€å¤§å¤„ç†å¸§æ•°ï¼Œ0è¡¨ç¤ºæ— é™åˆ¶")
    parser.add_argument("--no-save", action="store_true", 
                       help="ä¸ä¿å­˜å¤„ç†ç»“æœï¼ˆä»…æ˜¾ç¤ºï¼‰")
    
    # æ‘„åƒå¤´å‚æ•°
    parser.add_argument("--camera-index", type=int, default=0, 
                       help="æ‘„åƒå¤´ç´¢å¼•ï¼ˆé»˜è®¤: 0ï¼‰")
    parser.add_argument("--frame-width", type=int, default=1280, 
                       help="å¸§å®½åº¦ï¼ˆé»˜è®¤: 1280ï¼‰")
    parser.add_argument("--frame-height", type=int, default=720, 
                       help="å¸§é«˜åº¦ï¼ˆé»˜è®¤: 720ï¼‰")
    parser.add_argument("--fps", type=int, default=30, 
                       help="å¸§ç‡ï¼ˆé»˜è®¤: 30ï¼‰")
    parser.add_argument("--detection-interval", type=int, default=10, 
                       help="æ£€æµ‹é—´éš”å¸§æ•°ï¼ˆé»˜è®¤: 10ï¼‰")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model", type=str, default="yolov8s.pt", 
                       help="YOLOæ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤: yolov8s.ptï¼‰")
    parser.add_argument("--conf", type=float, default=0.5, 
                       help="æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰")
    parser.add_argument("--iou", type=float, default=0.45, 
                       help="NMS IoUé˜ˆå€¼ï¼ˆé»˜è®¤: 0.45ï¼‰")
    
    # å¤„ç†å‚æ•°
    parser.add_argument("--preprocess", action="store_true", 
                        help="å¯ç”¨è€—æ—¶çš„å›¾åƒå¢å¼º (é»˜è®¤å…³é—­)")
    parser.add_argument("--save-all", action="store_true", 
                       help="ä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœ")
    parser.add_argument("--no-display", action="store_true", 
                       help="ä¸æ˜¾ç¤ºå®æ—¶ç”»é¢")
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument("--output-dir", type=str, default="results", 
                       help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: resultsï¼‰")
    parser.add_argument("--output-format", type=str, default="jpg", 
                       choices=["jpg", "png", "bmp"], help="è¾“å‡ºå›¾ç‰‡æ ¼å¼")
    parser.add_argument("--save-json", action="store_true", 
                       help="ä¿å­˜JSONæ ¼å¼ç»“æœ")
    parser.add_argument("--save-txt", action="store_true", 
                       help="ä¿å­˜TXTæ ¼å¼ç»“æœ")
    
    # æ€§èƒ½å‚æ•°
    parser.add_argument("--device", type=str, default="cpu", 
                       choices=["cpu", "cuda", "mps"], 
                       help="è¿è¡Œè®¾å¤‡ï¼ˆé»˜è®¤: cpuï¼‰")
    parser.add_argument("--workers", type=int, default=4, 
                       help="æ•°æ®åŠ è½½çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰")
    parser.add_argument("--half", action="store_true", 
                       help="ä½¿ç”¨åŠç²¾åº¦æ¨ç†ï¼ˆFP16ï¼‰")
    
    # è°ƒè¯•å‚æ•°
    parser.add_argument("--debug", action="store_true", 
                       help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
    parser.add_argument("--verbose", action="store_true", 
                       help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")
    parser.add_argument("--version", action="version", 
                       version="è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ v1.0.0")
    
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("=" * 60)
    print("è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ v1.0.0 (å·²é›†æˆåœè½¦åœºç®¡ç†)")
    print("=" * 60)

    # å¤„ç†æ‘„åƒå¤´ç›¸å…³å‚æ•°
    if args.list_cameras:
        if CAMERA_MANAGER_AVAILABLE:
            list_all_cameras()
        else:
            print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    if args.camera_info is not None:
        if CAMERA_MANAGER_AVAILABLE:
            info = get_camera_info(args.camera_info)
            print_camera_info(info)
        else:
            print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    if args.test_camera is not None:
        if CAMERA_MANAGER_AVAILABLE:
            from camera_manager import test_camera
            test_camera(args.test_camera)
        else:
            print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    if args.find_best_camera:
        if CAMERA_MANAGER_AVAILABLE:
            best_camera = find_best_camera()
            if best_camera:
                print(f"æœ€ä½³æ‘„åƒå¤´: ç´¢å¼• {best_camera['index']}")
                print(f"åˆ†è¾¨ç‡: {best_camera['width']}x{best_camera['height']}")
                print(f"å¸§ç‡: {best_camera['fps']:.1f}fps")
            else:
                print("æœªæ‰¾åˆ°æ‘„åƒå¤´")
        else:
            print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return

    # æ£€æŸ¥å‚æ•°ç»„åˆ
    if not any([args.image, args.video, args.camera, args.batch]):
        # ä¼ é€’ parking_manager åˆ°èœå•
        run_interactive_menu(args, parking_manager)
        return
    
    # åˆ›å»ºç³»ç»Ÿ
    try:
        system = LicensePlateSystem(
            detection_model_path=args.model,
            detection_conf_threshold=args.conf,
            use_preprocessing=args.preprocess
        )
    except Exception as e:
        print(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥:")
        print("  1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("  2. ä¾èµ–åº“æ˜¯å¦å®‰è£…")
        print("  3. æ˜¯å¦æ­£ç¡®é…ç½®äº†CUDAï¼ˆå¦‚éœ€GPUåŠ é€Ÿï¼‰")
        return
    
    # æ ¹æ®è¾“å…¥æºå¤„ç†
    if args.image:
        # å¤„ç†å•å¼ å›¾ç‰‡
        process_image_mode(system, args, parking_manager)
    
    elif args.camera:
        # å¤„ç†æ‘„åƒå¤´å®æ—¶æ£€æµ‹
        process_camera_mode(system, args, parking_manager)
    
    elif args.video:
        # å¤„ç†è§†é¢‘æ–‡ä»¶
        process_video_mode(system, args, parking_manager)
    
    elif args.batch:
        # æ‰¹é‡å¤„ç†å›¾ç‰‡
        process_batch_mode(system, args) # æ‰¹é‡æ¨¡å¼é€šå¸¸ä¸è¿›è¡Œäº¤äº’å¼åœè½¦è®¡è´¹ï¼Œä¿æŒåŸæ ·


def run_interactive_menu(args, parking_manager):
    """è¿è¡Œäº¤äº’å¼èœå•ï¼ˆå¯é‡å¤é€‰æ‹©ï¼‰"""
    while True:
        print("\n" + "=" * 60)
        print("è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ - äº¤äº’æ¨¡å¼")
        print("=" * 60)
        print(f"åœè½¦åœºçŠ¶æ€: å·²å ç”¨ {100-parking_manager.get_available_spots()} / 100")
        print("è¯·é€‰æ‹©æ¨¡å¼:")
        print("  1. å¤„ç†å•å¼ å›¾ç‰‡ (å«åœè½¦è®¡è´¹)")
        print("  2. å¤„ç†è§†é¢‘æ–‡ä»¶ (å«åœè½¦è®¡è´¹)")
        print("  3. æ‘„åƒå¤´å®æ—¶æ£€æµ‹ (å«åœè½¦è®¡è´¹)")
        print("  4. æ‰¹é‡å¤„ç†å›¾ç‰‡ç›®å½•")
        print("  5. æ‘„åƒå¤´ç®¡ç†")
        print("  6. è¿è¡Œç³»ç»Ÿæµ‹è¯•")
        print("  7. åœè½¦åœºè®°å½•ç®¡ç†")
        print("  0. é€€å‡º")
        print("  M. è¿”å›ä¸»èœå•ï¼ˆé‡æ–°é€‰æ‹©æ¨¡å¼ï¼‰")
        print("  H. æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        print("=" * 60)
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-7, M, H): ").strip().lower()
        
        if choice == "0":
            print("é€€å‡ºç³»ç»Ÿ")
            break
        
        elif choice == "1":
            handle_image_mode(args, parking_manager)
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
        
        elif choice == "2":
            handle_video_mode(args, parking_manager)
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
        
        elif choice == "3":
            handle_camera_mode(args, parking_manager)
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
        
        elif choice == "4":
            handle_batch_mode(args)
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
        
        elif choice == "5":
            handle_camera_management_mode()
            continue  # ç»§ç»­æ˜¾ç¤ºæ‘„åƒå¤´ç®¡ç†å­èœå•
        
        elif choice == "6":
            run_tests()
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
            
        elif choice == "7":
            handle_parking_management_mode(parking_manager)
        
        elif choice == "m":
            continue  # ç»§ç»­å¾ªç¯ï¼Œæ˜¾ç¤ºä¸»èœå•
        
        elif choice == "h":
            print_help_info()
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")
        
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            input("\næŒ‰ Enter é”®è¿”å›èœå•...")

# æ‘„åƒå¤´ç®¡ç†å’Œå…¶ä»–è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜ï¼Œä»…åœ¨å‚æ•°ä¼ é€’å¤„åšå¾®è°ƒ
def handle_camera_management_mode():
    """æ‘„åƒå¤´ç®¡ç†å­èœå• (ä¿æŒä¸å˜)"""
    # ... (ä»£ç ä¸åŸæ–‡ä»¶ç›¸åŒ)
    while True:
        print("\n" + "=" * 60)
        print("æ‘„åƒå¤´ç®¡ç†")
        print("=" * 60)
        print("è¯·é€‰æ‹©åŠŸèƒ½:")
        print("  1. åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ‘„åƒå¤´")
        print("  2. æŸ¥çœ‹æ‘„åƒå¤´è¯¦ç»†ä¿¡æ¯")
        print("  3. æµ‹è¯•æ‘„åƒå¤´")
        print("  4. äº¤äº’å¼é€‰æ‹©æ‘„åƒå¤´")
        print("  5. å¯»æ‰¾æœ€ä½³æ‘„åƒå¤´")
        print("  6. æ‘„åƒå¤´å®æ—¶é¢„è§ˆ")
        print("  0. è¿”å›ä¸»èœå•")
        print("  B. è¿”å›ä¸Šä¸€å±‚ï¼ˆä¸»èœå•ï¼‰")
        print("=" * 60)
        
        sub_choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-6, B): ").strip().lower()
        
        if sub_choice == "0" or sub_choice == "b":
            print("è¿”å›ä¸»èœå•")
            break
        
        elif sub_choice == "1":
            if CAMERA_MANAGER_AVAILABLE:
                list_all_cameras()
            else:
                print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
            input("\næŒ‰ Enter é”®ç»§ç»­...")
        
        elif sub_choice == "2":
            handle_camera_info_mode()
        
        elif sub_choice == "3":
            handle_test_camera_mode()
        
        elif sub_choice == "4":
            handle_interactive_camera_selection()
        
        elif sub_choice == "5":
            handle_find_best_camera_mode()
            input("\næŒ‰ Enter é”®ç»§ç»­...")
        
        elif sub_choice == "6":
            handle_camera_preview_mode()
        
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            input("\næŒ‰ Enter é”®ç»§ç»­...")

def handle_image_mode(args, parking_manager):
    """å¤„ç†å›¾ç‰‡æ¨¡å¼"""
    print("\n=== å›¾ç‰‡å¤„ç†æ¨¡å¼ ===")
    
    while True:
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ (æˆ–è¾“å…¥ 'back' è¿”å›): ").strip()
        
        if image_path.lower() == 'back':
            print("è¿”å›ä¸»èœå•")
            break
        
        if not os.path.exists(image_path):
            print(f"é”™è¯¯ï¼šå›¾ç‰‡ä¸å­˜åœ¨ {image_path}")
            print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            continue
        
        # è¯¢é—®å‚æ•°
        use_preprocess = input("å¯ç”¨é¢„å¤„ç†ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
        output_dir = input("è¾“å‡ºç›®å½• (é»˜è®¤: results): ").strip()
        
        # è®¾ç½®å‚æ•°
        args.image = image_path
        args.no_preprocess = (use_preprocess == 'n')
        args.output_dir = output_dir if output_dir else "results"
        
        # åˆ›å»ºç³»ç»Ÿ
        try:
            system = LicensePlateSystem(
                detection_model_path=args.model,
                detection_conf_threshold=args.conf,
                use_preprocessing=args.preprocess
            )
            
            # å¤„ç†å›¾ç‰‡ (ä¼ é€’parking_manager)
            process_image_mode(system, args, parking_manager)
            
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
        another = input("\næ˜¯å¦å¤„ç†å¦ä¸€å¼ å›¾ç‰‡ï¼Ÿ(y/n): ").strip().lower()
        if another != 'y':
            break


def handle_video_mode(args, parking_manager):
    """å¤„ç†è§†é¢‘æ¨¡å¼"""
    print("\n=== è§†é¢‘å¤„ç†æ¨¡å¼ ===")
    
    while True:
        video_path = input("è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ (æˆ–è¾“å…¥ 'back' è¿”å›): ").strip()
        
        if video_path.lower() == 'back':
            print("è¿”å›ä¸»èœå•")
            break
        
        if not os.path.exists(video_path):
            print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ {video_path}")
            print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            continue
        
        # è¯¢é—®å‚æ•°
        print("\nè§†é¢‘å¤„ç†å‚æ•°:")
        start_time = input("å¼€å§‹æ—¶é—´(ç§’ï¼Œé»˜è®¤0): ").strip()
        duration = input("å¤„ç†æ—¶é•¿(ç§’ï¼Œé»˜è®¤æ•´ä¸ªè§†é¢‘): ").strip()
        detection_interval = input("æ£€æµ‹é—´éš”å¸§æ•°(é»˜è®¤10): ").strip()
        output_dir = input("è¾“å‡ºç›®å½• (é»˜è®¤: results/video): ").strip()
        
        # è®¾ç½®å‚æ•°
        args.video = video_path
        if start_time:
            args.video_start = float(start_time)
        if duration:
            args.video_duration = float(duration)
        if detection_interval:
            args.detection_interval = int(detection_interval)
        args.output_dir = output_dir if output_dir else "results/video"
        
        # åˆ›å»ºç³»ç»Ÿ
        try:
            system = LicensePlateSystem(
                detection_model_path=args.model,
                detection_conf_threshold=args.conf,
                use_preprocessing=args.preprocess
            )
            
            # å¤„ç†è§†é¢‘
            process_video_mode(system, args, parking_manager)
            
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å¤„ç†å…¶ä»–è§†é¢‘
        another = input("\næ˜¯å¦å¤„ç†å¦ä¸€ä¸ªè§†é¢‘ï¼Ÿ(y/n): ").strip().lower()
        if another != 'y':
            break


def handle_camera_mode(args, parking_manager):
    """å¤„ç†æ‘„åƒå¤´æ¨¡å¼ï¼ˆå®æ—¶è½¦ç‰Œæ£€æµ‹ï¼‰"""
    print("\n=== æ‘„åƒå¤´å®æ—¶æ£€æµ‹æ¨¡å¼ ===")
    
    # äº¤äº’å¼é€‰æ‹©æ‘„åƒå¤´
    if CAMERA_MANAGER_AVAILABLE:
        use_interactive = input("äº¤äº’å¼é€‰æ‹©æ‘„åƒå¤´ï¼Ÿ(y/n): ").strip().lower()
        if use_interactive == 'y':
            camera_info = select_camera_interactive()
            if camera_info is None:
                print("æ‘„åƒå¤´é€‰æ‹©å–æ¶ˆ")
                return
            args.camera_index = camera_info['index']
            if 'width' in camera_info:
                args.frame_width = camera_info['width']
            if 'height' in camera_info:
                args.frame_height = camera_info['height']
            if 'fps' in camera_info:
                args.fps = int(camera_info['fps'])
            if 'interval' in camera_info:
                args.detection_interval = camera_info['interval']
        else:
            # æ‰‹åŠ¨è¾“å…¥å‚æ•°
            camera_idx = input("æ‘„åƒå¤´ç´¢å¼•(é»˜è®¤0): ").strip()
            args.camera_index = int(camera_idx) if camera_idx else 0
    else:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
    
    # è¯¢é—®å…¶ä»–å‚æ•°
    print("\næ‘„åƒå¤´å‚æ•°è®¾ç½®:")
    width = input("å¸§å®½åº¦(é»˜è®¤1280): ").strip()
    height = input("å¸§é«˜åº¦(é»˜è®¤720): ").strip()
    fps = input("å¸§ç‡(é»˜è®¤30): ").strip()
    interval = input("æ£€æµ‹é—´éš”å¸§æ•°(é»˜è®¤10): ").strip()
    output_dir = input("è¾“å‡ºç›®å½• (é»˜è®¤: results/camera): ").strip()
    
    # è®¾ç½®å‚æ•°
    if width:
        args.frame_width = int(width)
    if height:
        args.frame_height = int(height)
    if fps:
        args.fps = int(fps)
    if interval:
        args.detection_interval = int(interval)
    args.output_dir = output_dir if output_dir else "results/camera"
    args.camera = True
    
    # åˆ›å»ºç³»ç»Ÿ
    try:
        system = LicensePlateSystem(
            detection_model_path=args.model,
            detection_conf_threshold=args.conf,
            use_preprocessing=args.preprocess
        )
        
        # å¤„ç†æ‘„åƒå¤´
        process_camera_mode(system, args, parking_manager)
        
    except Exception as e:
        print(f"å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# æ‰¹é‡å¤„ç†ã€æ‘„åƒå¤´ä¿¡æ¯æŸ¥è¯¢ç­‰ä¿æŒä¸å˜
def handle_batch_mode(args):
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """å¤„ç†æ‰¹é‡æ¨¡å¼"""
    print("\n=== æ‰¹é‡å¤„ç†æ¨¡å¼ ===")
    
    while True:
        batch_dir = input("è¯·è¾“å…¥å›¾ç‰‡ç›®å½•è·¯å¾„ (æˆ–è¾“å…¥ 'back' è¿”å›): ").strip()
        
        if batch_dir.lower() == 'back':
            print("è¿”å›ä¸»èœå•")
            break
        
        if not os.path.exists(batch_dir):
            print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ {batch_dir}")
            print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            continue
        
        # è¯¢é—®å‚æ•°
        output_dir = input("è¾“å‡ºç›®å½• (é»˜è®¤: results/batch): ").strip()
        
        # è®¾ç½®å‚æ•°
        args.batch = batch_dir
        args.output_dir = output_dir if output_dir else "results/batch"
        
        # åˆ›å»ºç³»ç»Ÿ
        try:
            system = LicensePlateSystem(
                detection_model_path=args.model,
                detection_conf_threshold=args.conf,
                use_preprocessing=args.preprocess
            )
            
            # æ‰¹é‡å¤„ç†
            process_batch_mode(system, args)
            
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­å¤„ç†å…¶ä»–ç›®å½•
        another = input("\næ˜¯å¦å¤„ç†å¦ä¸€ä¸ªç›®å½•ï¼Ÿ(y/n): ").strip().lower()
        if another != 'y':
            break

def handle_camera_info_mode():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """å¤„ç†æ‘„åƒå¤´ä¿¡æ¯æŸ¥è¯¢æ¨¡å¼"""
    print("\n=== æ‘„åƒå¤´ä¿¡æ¯æŸ¥è¯¢ ===")
    
    if not CAMERA_MANAGER_AVAILABLE:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    while True:
        camera_idx = input("è¯·è¾“å…¥æ‘„åƒå¤´ç´¢å¼• (æˆ–è¾“å…¥ 'list' åˆ—å‡ºæ‰€æœ‰, 'back' è¿”å›): ").strip().lower()
        
        if camera_idx == 'back':
            print("è¿”å›ä¸Šä¸€çº§")
            break
        
        elif camera_idx == 'list':
            list_all_cameras()
            continue
        
        try:
            idx = int(camera_idx)
            info = get_camera_info(idx)
            print_camera_info(info)
            
            # è¯¢é—®æ˜¯å¦æµ‹è¯•æ­¤æ‘„åƒå¤´
            test = input("\næ˜¯å¦æµ‹è¯•æ­¤æ‘„åƒå¤´ï¼Ÿ(y/n): ").strip().lower()
            if test == 'y':
                if CAMERA_MANAGER_AVAILABLE:
                    from camera_manager import test_camera
                    test_camera(idx)
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ç´¢å¼•")

def handle_test_camera_mode():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """å¤„ç†æ‘„åƒå¤´æµ‹è¯•æ¨¡å¼"""
    print("\n=== æ‘„åƒå¤´æµ‹è¯• ===")
    
    if not CAMERA_MANAGER_AVAILABLE:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    while True:
        camera_idx = input("è¯·è¾“å…¥æ‘„åƒå¤´ç´¢å¼• (æˆ–è¾“å…¥ 'back' è¿”å›): ").strip().lower()
        
        if camera_idx == 'back':
            print("è¿”å›ä¸Šä¸€çº§")
            break
        
        try:
            idx = int(camera_idx)
            from camera_manager import test_camera
            test_camera(idx)
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ç´¢å¼•")

def handle_interactive_camera_selection():
    # ... (ä¿æŒåŸä»£ç ä¸å˜ï¼Œä½†åœ¨è°ƒç”¨process_camera_modeæ—¶ä¼šå‡ºé”™ï¼Œå› ä¸ºæ²¡ä¼ managerï¼Œè¿™é‡Œåšç®€å•ä¿®å¤)
    """å¤„ç†äº¤äº’å¼æ‘„åƒå¤´é€‰æ‹©"""
    print("\n=== äº¤äº’å¼æ‘„åƒå¤´é€‰æ‹© ===")
    
    if not CAMERA_MANAGER_AVAILABLE:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    camera_info = select_camera_interactive()
    if camera_info is not None:
        print(f"\nå·²é€‰æ‹©æ‘„åƒå¤´:")
        print(f"  ç´¢å¼•: {camera_info['index']}")
        print(f"  åç§°: {camera_info.get('name', 'æœªçŸ¥')}")
        if 'width' in camera_info and 'height' in camera_info:
            print(f"  åˆ†è¾¨ç‡: {camera_info['width']}x{camera_info['height']}")
        if 'fps' in camera_info:
            print(f"  å¸§ç‡: {camera_info['fps']:.1f}fps")
        
        # è¯¢é—®æ˜¯å¦ç«‹å³å¼€å§‹è½¦ç‰Œæ£€æµ‹
        start_detection = input("\næ˜¯å¦ç«‹å³å¼€å§‹è½¦ç‰Œæ£€æµ‹ï¼Ÿ(y/n): ").strip().lower()
        if start_detection == 'y':
            # åˆ›å»ºä¸´æ—¶å‚æ•°å¯¹è±¡
            class Args:
                pass
            args = Args()
            args.camera_index = camera_info['index']
            args.frame_width = camera_info.get('width', 1280)
            args.frame_height = camera_info.get('height', 720)
            args.fps = int(camera_info.get('fps', 30))
            args.detection_interval = camera_info.get('interval', 10)
            args.output_dir = "results/camera"
            args.model = "yolov8s.pt"
            args.conf = 0.5
            args.no_preprocess = False
            args.preprocess = False # ä¿®å¤
            
            # åˆ›å»ºç³»ç»Ÿå¹¶å¼€å§‹æ£€æµ‹
            try:
                system = LicensePlateSystem(
                    detection_model_path=args.model,
                    detection_conf_threshold=args.conf,
                    use_preprocessing=args.preprocess
                )
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ²¡æœ‰ parking_manager å®ä¾‹ï¼Œæ–°å»ºä¸€ä¸ªä¸´æ—¶çš„
                temp_pm = ParkingManager()
                process_camera_mode(system, args, temp_pm)
            except Exception as e:
                print(f"å¯åŠ¨è½¦ç‰Œæ£€æµ‹å¤±è´¥: {e}")

def handle_find_best_camera_mode():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """å¤„ç†å¯»æ‰¾æœ€ä½³æ‘„åƒå¤´æ¨¡å¼"""
    print("\n=== å¯»æ‰¾æœ€ä½³æ‘„åƒå¤´ ===")
    
    if not CAMERA_MANAGER_AVAILABLE:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        return
    
    best_camera = find_best_camera()
    if best_camera:
        print(f"æœ€ä½³æ‘„åƒå¤´: ç´¢å¼• {best_camera['index']}")
        print(f"åç§°: {best_camera.get('name', 'æœªçŸ¥')}")
        print(f"åˆ†è¾¨ç‡: {best_camera['width']}x{best_camera['height']}")
        print(f"å¸§ç‡: {best_camera['fps']:.1f}fps")
        
        # è¯¢é—®æ˜¯å¦æµ‹è¯•æ­¤æ‘„åƒå¤´
        test = input("\næ˜¯å¦æµ‹è¯•æ­¤æ‘„åƒå¤´ï¼Ÿ(y/n): ").strip().lower()
        if test == 'y':
            from camera_manager import test_camera
            test_camera(best_camera['index'])
    else:
        print("æœªæ‰¾åˆ°æ‘„åƒå¤´")

def handle_camera_preview_mode():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """æ‘„åƒå¤´å®æ—¶é¢„è§ˆæ¨¡å¼"""
    print("\n=== æ‘„åƒå¤´å®æ—¶é¢„è§ˆ ===")
    
    if not CAMERA_MANAGER_AVAILABLE:
        print("æ‘„åƒå¤´ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨")
        # å°è¯•ä½¿ç”¨é»˜è®¤æ–¹æ³•
        camera_idx = input("è¯·è¾“å…¥æ‘„åƒå¤´ç´¢å¼• (é»˜è®¤0): ").strip()
        camera_idx = int(camera_idx) if camera_idx else 0
        test_single_camera(camera_idx)
        return
    
    # å…ˆåˆ—å‡ºæ‰€æœ‰æ‘„åƒå¤´
    list_all_cameras()
    
    # é€‰æ‹©æ‘„åƒå¤´
    camera_idx = input("\nè¯·è¾“å…¥è¦é¢„è§ˆçš„æ‘„åƒå¤´ç´¢å¼• (æˆ–è¾“å…¥ 'back' è¿”å›): ").strip().lower()
    
    if camera_idx == 'back':
        print("è¿”å›ä¸Šä¸€çº§")
        return
    
    try:
        idx = int(camera_idx)
        from camera_manager import test_camera
        test_camera(idx)
    except ValueError:
        print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ç´¢å¼•")

def print_help_info():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("å¸®åŠ©ä¿¡æ¯")
    print("=" * 60)
    print("ç³»ç»ŸåŠŸèƒ½:")
    print("  1. å›¾ç‰‡å¤„ç† - è¯†åˆ«å•å¼ å›¾ç‰‡ä¸­çš„è½¦ç‰Œ")
    print("  2. è§†é¢‘å¤„ç† - è¯†åˆ«è§†é¢‘æ–‡ä»¶ä¸­çš„è½¦ç‰Œ")
    print("  3. å®æ—¶æ£€æµ‹ - é€šè¿‡æ‘„åƒå¤´å®æ—¶æ£€æµ‹è½¦ç‰Œ")
    print("  4. æ‰¹é‡å¤„ç† - å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡")
    print("  5. æ‘„åƒå¤´ç®¡ç† - æŸ¥çœ‹å’Œç®¡ç†æ‘„åƒå¤´è®¾å¤‡")
    print("  6. ç³»ç»Ÿæµ‹è¯• - è¿è¡Œç³»ç»Ÿè¯Šæ–­å’Œæµ‹è¯•")
    print("  7. åœè½¦åœºç®¡ç† - æ‰‹åŠ¨ç®¡ç†åœè½¦åœºè®°å½•")
    print()
    print("æ‘„åƒå¤´ç®¡ç†åŠŸèƒ½:")
    print("  1. åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ‘„åƒå¤´")
    print("  2. æŸ¥çœ‹æ‘„åƒå¤´è¯¦ç»†ä¿¡æ¯")
    print("  3. æµ‹è¯•æ‘„åƒå¤´")
    print("  4. äº¤äº’å¼é€‰æ‹©æ‘„åƒå¤´")
    print("  5. å¯»æ‰¾æœ€ä½³æ‘„åƒå¤´")
    print("  6. æ‘„åƒå¤´å®æ—¶é¢„è§ˆ")
    print()
    print("å¸¸ç”¨å‘½ä»¤:")
    print("  python main.py --image test.jpg")
    print("  python main.py --video test.mp4")
    print("  python main.py --camera")
    print("  python main.py --batch images/")
    print()
    print("æ›´å¤šé€‰é¡¹ä½¿ç”¨: python main.py --help")
    print("=" * 60)

# ==========================================
# ä¿®æ”¹ï¼šå›¾ç‰‡å¤„ç†æ¨¡å¼ï¼Œå¢åŠ åœè½¦äº¤äº’
# ==========================================
def process_image_mode(system, args, parking_manager=None):
    """å¤„ç†å›¾ç‰‡æ¨¡å¼"""
    print(f"å¤„ç†å›¾ç‰‡: {args.image}")
    
    if not os.path.exists(args.image):
        print(f"é”™è¯¯ï¼šå›¾ç‰‡ä¸å­˜åœ¨ {args.image}")
        return
    
    try:
        results = system.process_image(
            image_path=args.image,
            save_results=True,
            output_dir=args.output_dir
        )
        
        if results:
            print(f"\nâœ“ å¤„ç†å®Œæˆï¼æ£€æµ‹åˆ° {len(results)} ä¸ªè½¦ç‰Œ")
            
            # æ˜¾ç¤ºç»“æœ
            for i, result in enumerate(results, 1):
                plate_text = result['plate_text']
                print(f"  {i}. {plate_text} ({result['plate_type']}) "
                      f"ç½®ä¿¡åº¦: {result['ocr_confidence']:.2f}")
                
                # åœè½¦è®¡è´¹äº¤äº’
                if parking_manager and plate_text != "æœªçŸ¥":
                    handle_parking_interaction(parking_manager, plate_text)
        else:
            print("æœªæ£€æµ‹åˆ°è½¦ç‰Œ")
            
    except Exception as e:
        print(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()

# ==========================================
# ä¿®æ”¹ï¼šæ‘„åƒå¤´å¤„ç†æ¨¡å¼

def process_camera_mode(system, args, parking_manager=None):
    """å¤„ç†æ‘„åƒå¤´æ¨¡å¼ (æ”¯æŒåœè½¦äº¤äº’)"""
    print("å¯åŠ¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹ (æŒ‰ 'q' é€€å‡º, è¯†åˆ«åˆ°è½¦ç‰Œåä¼šè¯¢é—®åœè½¦æ“ä½œ)...")
    
    cap = cv2.VideoCapture(args.camera_index)
    if not cap.isOpened():
        print(f"é”™è¯¯: æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {args.camera_index}")
        return

    # è®¾ç½®å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, args.frame_width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, args.frame_height)
    cap.set(cv2.CAP_PROP_FPS, args.fps)

    frame_count = 0
    detection_interval = args.detection_interval
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            frame_count += 1
            display_frame = frame.copy()
            
            # å®šæ—¶æ£€æµ‹
            if frame_count % detection_interval == 0:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºæ£€æµ‹
                temp_path = "temp_cam_frame.jpg"
                cv2.imwrite(temp_path, frame)
                
                # 1. æ£€æµ‹è½¦ç‰Œ
                plates_info = system.detector.detect_all_and_rectify(temp_path)
                
                if plates_info:
                    for i, plate_info in enumerate(plates_info):
                        # 2. è¯†åˆ«è½¦ç‰Œ
                        result = system._process_camera_detection(frame, plate_info, i)
                        
                        plate_text = result.get('plate_text', 'æœªçŸ¥')
                        
                        # 3. å¦‚æœè¯†åˆ«æˆåŠŸï¼Œæ ‡æ³¨å¹¶è¯¢é—®
                        if plate_text != "æœªçŸ¥":
                            # æ ‡æ³¨ç”»é¢
                            display_frame = system._annotate_camera_frame(display_frame, result)
                            cv2.imshow('License Plate System', display_frame)
                            cv2.waitKey(1) # åˆ·æ–°æ˜¾ç¤º
                            
                            # æš‚åœå¹¶è¯¢é—®ç”¨æˆ·
                            if parking_manager:
                                print("\n>>> æš‚åœå®æ—¶ç”»é¢ä»¥è¿›è¡Œåœè½¦æ“ä½œ <<<")
                                handle_parking_interaction(parking_manager, plate_text)
                                print(">>> æ¢å¤å®æ—¶ç”»é¢ <<<")
                
                # æ¸…ç†
                try: os.remove(temp_path)
                except: pass

            cv2.imshow('License Plate System', display_frame)
            
            # æŒ‰ 'q' é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"æ‘„åƒå¤´è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cap.release()
        cv2.destroyAllWindows()


def test_single_camera(camera_index, test_duration=5):
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """æµ‹è¯•å•ä¸ªæ‘„åƒå¤´"""
    print(f"\næµ‹è¯•æ‘„åƒå¤´ {camera_index}...")
    print("æŒ‰ 'q' é”®é€€å‡ºæµ‹è¯•")
    
    cap = None
    try:
        # å°è¯•ä¸åŒçš„åç«¯
        backends_to_try = [cv2.CAP_ANY, cv2.CAP_DSHOW, cv2.CAP_MSMF]
        
        for backend in backends_to_try:
            try:
                cap = cv2.VideoCapture(camera_index, backend)
                if cap.isOpened():
                    print(f"  ä½¿ç”¨åç«¯: {backend}")
                    break
            except:
                continue
        
        if not cap or not cap.isOpened():
            print("  æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        # è·å–å®é™…å‚æ•°
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        print(f"  å®é™…å‚æ•°: {width}x{height} @ {fps}fps")
        print("  æ­£åœ¨æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢...")
        
        import time
        start_time = time.time()
        frame_count = 0
        
        while time.time() - start_time < test_duration:
            ret, frame = cap.read()
            if not ret:
                print("  æ— æ³•è¯»å–å¸§")
                break
            
            frame_count += 1
            
            # æ˜¾ç¤ºå¸§
            cv2.putText(frame, f"Camera {camera_index}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, f"{width}x{height}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, f"FPS: {fps}", (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.imshow(f'Camera Test - Index {camera_index}', frame)
            
            # æŒ‰'q'é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        elapsed_time = time.time() - start_time
        if elapsed_time > 0:
            actual_fps = frame_count / elapsed_time
            print(f"  å®é™…å¸§ç‡: {actual_fps:.1f} fps")
            print(f"  æ€»å¸§æ•°: {frame_count}")
        
        print("  æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"  æµ‹è¯•å‡ºé”™: {e}")
    finally:
        if cap:
            cap.release()
        cv2.destroyAllWindows()


# ==========================================
# ä¿®æ”¹ï¼šè§†é¢‘å¤„ç†æ¨¡å¼ï¼Œå¢åŠ åœè½¦äº¤äº’
# ==========================================
def process_video_mode(system, args, parking_manager=None):
    """å¤„ç†è§†é¢‘æ¨¡å¼"""
    print(f"å¤„ç†è§†é¢‘: {args.video}")
    
    if not os.path.exists(args.video):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ {args.video}")
        return
    
    # å¼ºåˆ¶ä½¿ç”¨Fallbackæ¨¡å¼æ¥æ”¯æŒäº¤äº’ï¼ˆå› ä¸ºæ— æ³•ä¿®æ”¹ video_processor.pyï¼‰
    # æˆ–è€…æˆ‘ä»¬åœ¨Fallbacké€»è¾‘é‡ŒåŠ ï¼Œå¦‚æœ VideoLicensePlateProcessor å¯ç”¨ï¼Œ
    # æˆ‘ä»¬å°±æ²¡åŠæ³•åœ¨è¯¥æ¨¡å—å†…éƒ¨æš‚åœè§†é¢‘æ¥é—®ç”¨æˆ·ã€‚
    # ä¸ºäº†æ»¡è¶³éœ€æ±‚ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰å¾ªç¯ï¼Œæˆ–è€…ä»…åœ¨ä½¿ç”¨Fallbackæ—¶æ”¯æŒã€‚
    
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æœ¬æ–‡ä»¶è‡ªå¸¦çš„è§†é¢‘å¤„ç†é€»è¾‘ï¼ˆåŸä»£ç ä¸­çš„elseéƒ¨åˆ†ï¼‰ï¼Œ
    # å¹¶å°†å…¶ä½œä¸ºä¸»è¦çš„é€»è¾‘ä»¥æ”¯æŒåœè½¦åŠŸèƒ½ã€‚
    
    print("ä½¿ç”¨å¸¦äº¤äº’åŠŸèƒ½çš„è§†é¢‘å¤„ç†æ¨¡å¼...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    video_output_dir = os.path.join(args.output_dir, "video")
    os.makedirs(video_output_dir, exist_ok=True)
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(args.video)
    if not cap.isOpened():
        print(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {args.video}")
        return
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    print(f"è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps}fps")
    
    # å¤„ç†è§†é¢‘
    frame_idx = 0
    detection_count = 0
    unique_plates = set()
    processed_plates_in_session = set() # æœ¬æ¬¡ä¼šè¯å·²å¤„ç†çš„è½¦ç‰Œï¼Œé¿å…è§†é¢‘ä¸­åŒä¸€è¾†è½¦é‡å¤é—®è¯¢
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_idx += 1
            
            # æ¯Nå¸§å¤„ç†ä¸€æ¬¡
            if frame_idx % (args.detection_interval if hasattr(args, 'detection_interval') else 30) == 0:
                # ä¿å­˜ä¸´æ—¶å¸§
                temp_path = f"temp_frame_{frame_idx}.jpg"
                cv2.imwrite(temp_path, frame)
                
                # æ£€æµ‹è½¦ç‰Œ
                plates_info = system.detector.detect_all_and_rectify(temp_path)
                
                if plates_info:
                    for plate_info in plates_info:
                        detection_count += 1
                        
                        # å¤„ç†è½¦ç‰Œ
                        result = system._process_camera_detection(frame, plate_info, detection_count)
                        plate_text = result.get('plate_text', 'æœªçŸ¥')
                        
                        if plate_text != "æœªçŸ¥":
                            unique_plates.add(plate_text)
                            
                            # ä¿å­˜ç»“æœå¸§
                            if not hasattr(args, 'no_save') or not args.no_save:
                                result_frame = system._annotate_camera_frame(frame.copy(), result)
                                cv2.imwrite(f"{video_output_dir}/frame_{frame_idx}_plate_{detection_count}.jpg", result_frame)
                                # ä¹Ÿæ˜¾ç¤ºä¸€ä¸‹
                                cv2.imshow('Video Processing', result_frame)
                                cv2.waitKey(1)
                            
                            # åœè½¦äº¤äº’é€»è¾‘ï¼šä»…å½“è¯¥è½¦ç‰Œåœ¨è§†é¢‘ä¸­ç¬¬ä¸€æ¬¡å‡ºç°æ—¶è¯¢é—®ï¼Œæˆ–è€…ç”¨æˆ·æ¯æ¬¡éƒ½æƒ³è¢«é—®
                            # è¿™é‡Œè®¾å®šä¸ºï¼šå¦‚æœæ˜¯è§†é¢‘é‡Œçš„æ–°è½¦ç‰Œï¼Œå°±é—®ä¸€æ¬¡
                            if parking_manager and plate_text not in processed_plates_in_session:
                                print(f"\n>>> è§†é¢‘ç¬¬ {frame_idx} å¸§æ£€æµ‹åˆ°æ–°è½¦ç‰Œ <<<")
                                handle_parking_interaction(parking_manager, plate_text)
                                processed_plates_in_session.add(plate_text)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(temp_path)
                except:
                    pass
            
            # æ˜¾ç¤ºè¿›åº¦
            if frame_idx % 100 == 0:
                print(f"å·²å¤„ç† {frame_idx}/{total_frames} å¸§")
                
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­è§†é¢‘å¤„ç†")
    finally:
        cap.release()
        cv2.destroyAllWindows()
    
    print(f"\nè§†é¢‘å¤„ç†å®Œæˆ:")
    print(f"  æ€»å¸§æ•°: {total_frames}")
    print(f"  æ£€æµ‹åˆ°è½¦ç‰Œæ•°: {detection_count}")
    print(f"  å”¯ä¸€è½¦ç‰Œæ•°: {len(unique_plates)}")
    print(f"  è¾“å‡ºç›®å½•: {video_output_dir}")
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    with open(f"{video_output_dir}/summary.txt", "w", encoding="utf-8") as f:
        f.write(f"è§†é¢‘æ–‡ä»¶: {args.video}\n")
        f.write(f"æ€»å¸§æ•°: {total_frames}\n")
        f.write(f"æ£€æµ‹åˆ°è½¦ç‰Œæ•°: {detection_count}\n")
        f.write(f"å”¯ä¸€è½¦ç‰Œæ•°: {len(unique_plates)}\n")
        f.write(f"æ£€æµ‹åˆ°çš„è½¦ç‰Œ: {', '.join(unique_plates)}\n")


def process_batch_mode(system, args):
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """æ‰¹é‡å¤„ç†æ¨¡å¼"""
    print(f"æ‰¹é‡å¤„ç†ç›®å½•: {args.batch}")
    
    if not os.path.exists(args.batch):
        print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ {args.batch}")
        return
    
    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(Path(args.batch).glob(f"*{ext}"))
        image_files.extend(Path(args.batch).glob(f"*{ext.upper()}"))
    
    if not image_files:
        print("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    batch_output_dir = os.path.join(args.output_dir, "batch")
    os.makedirs(batch_output_dir, exist_ok=True)
    
    # æ‰¹é‡å¤„ç†
    total_plates = 0
    success_count = 0
    
    for i, image_file in enumerate(image_files, 1):
        print(f"\n[{i}/{len(image_files)}] å¤„ç†: {image_file.name}")
        
        try:
            # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå­ç›®å½•
            image_output_dir = os.path.join(batch_output_dir, image_file.stem)
            os.makedirs(image_output_dir, exist_ok=True)
            
            # å¤„ç†å›¾ç‰‡ (æ‰¹é‡æ¨¡å¼é€šå¸¸ä¸åŠ äº¤äº’)
            results = system.process_image(
                image_path=str(image_file),
                save_results=True,
                output_dir=image_output_dir
            )
            
            if results:
                success_count += 1
                total_plates += len(results)
                print(f"  âœ“ æ£€æµ‹åˆ° {len(results)} ä¸ªè½¦ç‰Œ")
            else:
                print(f"  âœ— æœªæ£€æµ‹åˆ°è½¦ç‰Œ")
                
        except Exception as e:
            print(f"  å¤„ç†å¤±è´¥: {e}")
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "=" * 60)
    print("æ‰¹é‡å¤„ç†å®Œæˆ")
    print("=" * 60)
    print(f"å¤„ç†å›¾ç‰‡æ•°: {len(image_files)}")
    print(f"æˆåŠŸæ£€æµ‹å›¾ç‰‡æ•°: {success_count}")
    print(f"æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°: {total_plates}")
    print(f"è¾“å‡ºç›®å½•: {batch_output_dir}")


def run_tests():
    # ... (ä¿æŒåŸä»£ç ä¸å˜)
    """è¿è¡Œç³»ç»Ÿæµ‹è¯•"""
    print("è¿è¡Œç³»ç»Ÿæµ‹è¯•...")
    
    # æ£€æŸ¥ä¾èµ–
    print("\n1. æ£€æŸ¥ä¾èµ–åº“:")
    try:
        import torch
        print(f"  âœ“ PyTorch: {torch.__version__}")
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            for i in range(device_count):
                print(f"    GPU {i}: {torch.cuda.get_device_name(i)}")
        else:
            print(f"    è®¾å¤‡: CPU")
    except:
        print("  âœ— PyTorch: æœªå®‰è£…")
    
    try:
        print(f"  âœ“ OpenCV: {cv2.__version__}")
    except:
        print("  âœ— OpenCV: æœªå®‰è£…")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print("\n2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶:")
    model_files = ["yolov8s.pt", "yolov8n.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"]
    found_models = []
    for model_file in model_files:
        if os.path.exists(model_file):
            file_size = os.path.getsize(model_file) / (1024*1024)  # è½¬æ¢ä¸ºMB
            print(f"  âœ“ {model_file}: å­˜åœ¨ ({file_size:.1f} MB)")
            found_models.append(model_file)
        else:
            print(f"  âœ— {model_file}: ä¸å­˜åœ¨")
    
    if found_models:
        print(f"    æ‰¾åˆ° {len(found_models)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    else:
        print("    è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
        print("    è¯·ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½:")
        print("    https://github.com/ultralytics/ultralytics")
    
    # æ£€æŸ¥æ‘„åƒå¤´ - æ”¹è¿›ç‰ˆæœ¬
    print("\n3. æ£€æŸ¥æ‘„åƒå¤´:")
    available_cameras = []
    max_check_index = 10  # æœ€å¤šæ£€æŸ¥10ä¸ªæ‘„åƒå¤´ç´¢å¼•
    
    # å®šä¹‰è¦å°è¯•çš„åç«¯åˆ—è¡¨
    backends = [
        cv2.CAP_DSHOW,    # DirectShow (Windows)
        cv2.CAP_MSMF,     # Microsoft Media Foundation (Windows)
        cv2.CAP_V4L2,     # Video4Linux (Linux)
        cv2.CAP_ANY,      # è‡ªåŠ¨é€‰æ‹©
    ]
    
    backend_names = {
        cv2.CAP_DSHOW: "DSHOW",
        cv2.CAP_MSMF: "MSMF",
        cv2.CAP_V4L2: "V4L2",
        cv2.CAP_ANY: "AUTO"
    }
    
    print("  æ­£åœ¨æ‰«ææ‘„åƒå¤´...")
    
    for i in range(max_check_index):
        camera_found = False
        best_backend = None
        camera_info = None
        
        # å°è¯•ä¸åŒçš„åç«¯
        for backend in backends:
            try:
                # ä½¿ç”¨try-excepté¿å…å´©æºƒ
                cap = cv2.VideoCapture(i, backend)
                if cap.isOpened():
                    # å°è¯•è¯»å–ä¸€å¸§
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        # æˆåŠŸè¯»å–åˆ°å¸§
                        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)
                        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)
                        fps = int(cap.get(cv2.CAP_PROP_FPS) or 0)
                        
                        # å°è¯•å¤šæ¬¡è¯»å–ä»¥è·å–æ›´å‡†ç¡®çš„fps
                        if fps == 0:
                            import time
                            start_time = time.time()
                            frame_count = 0
                            for _ in range(30):  # è¯»å–30å¸§è®¡ç®—fps
                                ret, _ = cap.read()
                                if ret:
                                    frame_count += 1
                            end_time = time.time()
                            if end_time - start_time > 0:
                                fps = int(frame_count / (end_time - start_time))
                        
                        camera_info = {
                            'index': i,
                            'backend': backend,
                            'backend_name': backend_names.get(backend, str(backend)),
                            'width': width if width > 0 else "æœªçŸ¥",
                            'height': height if height > 0 else "æœªçŸ¥",
                            'fps': fps if fps > 0 else "æœªçŸ¥",
                            'working': True
                        }
                        
                        best_backend = backend
                        camera_found = True
                        
                        # é‡Šæ”¾æ‘„åƒå¤´
                        cap.release()
                        break  # æ‰¾åˆ°å¯ç”¨åç«¯å°±åœæ­¢å°è¯•
                    else:
                        cap.release()
            except Exception as e:
                # å¿½ç•¥ç‰¹å®šåç«¯é”™è¯¯ï¼Œç»§ç»­å°è¯•å…¶ä»–åç«¯
                pass
        
        if camera_found and camera_info:
            # è·å–æ‘„åƒå¤´åç§°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            camera_name = f"æ‘„åƒå¤´ {i}"
            try:
                # å°è¯•ä½¿ç”¨æœ€åä¸€ä¸ªæˆåŠŸçš„åç«¯å†æ¬¡æ‰“å¼€ä»¥è·å–åç§°
                if best_backend:
                    cap = cv2.VideoCapture(i, best_backend)
                    if cap.isOpened():
                        # åœ¨æŸäº›ç³»ç»Ÿä¸Šå¯ä»¥è·å–è®¾å¤‡åç§°
                        try:
                            # å°è¯•é€šè¿‡å±æ€§è·å–åç§°
                            name = cap.get(cv2.CAP_PROP_BACKEND_NAME)
                            if name:
                                camera_name = f"æ‘„åƒå¤´ {i} ({name})"
                        except:
                            pass
                        cap.release()
            except:
                pass
            
            print(f"  âœ“ {camera_name} ({camera_info['backend_name']}) - "
                  f"{camera_info['width']}x{camera_info['height']} @ {camera_info['fps']}fps: å¯ç”¨")
            
            available_cameras.append({
                'index': i,
                'name': camera_name,
                'backend': camera_info['backend_name'],
                'width': camera_info['width'],
                'height': camera_info['height'],
                'fps': camera_info['fps']
            })
        else:
            # å¦‚æœå‰å‡ ä¸ªéƒ½æ²¡æœ‰æ‘„åƒå¤´ï¼Œæå‰ç»“æŸ
            if i > 3 and len(available_cameras) == 0:
                # æ£€æŸ¥å‰4ä¸ªéƒ½æ²¡æœ‰æ‘„åƒå¤´ï¼Œå°±ä¸å†ç»§ç»­æ£€æŸ¥å¤ªå¤š
                if i >= 5:
                    print(f"  æ‰«æåˆ°ç´¢å¼• {i}ï¼Œæœªå‘ç°æ›´å¤šæ‘„åƒå¤´")
                    break
    
    if available_cameras:
        print(f"\n    æ‰¾åˆ° {len(available_cameras)} ä¸ªå¯ç”¨æ‘„åƒå¤´")
        print("\n    å¯ç”¨æ‘„åƒå¤´åˆ—è¡¨:")
        for cam in available_cameras:
            print(f"      ç´¢å¼• {cam['index']}: {cam['name']}")
            print(f"        åç«¯: {cam['backend']}")
            print(f"        åˆ†è¾¨ç‡: {cam['width']}x{cam['height']}")
            print(f"        å¸§ç‡: {cam['fps']}fps")
        
        # æä¾›ä¸€ä¸ªç®€å•çš„æ‘„åƒå¤´æµ‹è¯•åŠŸèƒ½
        print("\n    å¿«é€Ÿæ‘„åƒå¤´æµ‹è¯•ï¼ˆè¾“å…¥ 'q' é€€å‡ºï¼‰:")
        if len(available_cameras) > 0:
            test_cam = input(f"    æ˜¯å¦æµ‹è¯•æ‘„åƒå¤´ {available_cameras[0]['index']}? (y/n): ").strip().lower()
            if test_cam == 'y':
                test_single_camera(available_cameras[0]['index'])
    else:
        print("    æœªæ‰¾åˆ°å¯ç”¨æ‘„åƒå¤´")
        print("\n    å¯èƒ½çš„åŸå› :")
        print("      1. æ‘„åƒå¤´æœªè¿æ¥æˆ–æœªæ­£ç¡®å®‰è£…")
        print("      2. æ‘„åƒå¤´é©±åŠ¨ç¨‹åºæœªæ­£ç¡®å®‰è£…")
        print("      3. æ‘„åƒå¤´è¢«å…¶ä»–ç¨‹åºå ç”¨")
        print("      4. æƒé™é—®é¢˜ï¼ˆLinux/Macéœ€è¦æƒé™ï¼‰")
        print("\n    è§£å†³æ–¹æ³•:")
        print("      1. æ£€æŸ¥æ‘„åƒå¤´ç‰©ç†è¿æ¥")
        print("      2. é‡å¯ç”µè„‘")
        print("      3. æ›´æ–°æ‘„åƒå¤´é©±åŠ¨ç¨‹åº")
        print("      4. å…³é—­å…¶ä»–ä½¿ç”¨æ‘„åƒå¤´çš„ç¨‹åº")
        print("      5. åœ¨Linux/Macä¸Šå°è¯•: sudo chmod 666 /dev/video*")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è™šæ‹Ÿæ‘„åƒå¤´è½¯ä»¶
        print("\n    è™šæ‹Ÿæ‘„åƒå¤´é€‰é¡¹:")
        print("      1. OBS Studio (å¯ä»¥åˆ›å»ºè™šæ‹Ÿæ‘„åƒå¤´)")
        print("      2. ManyCam")
        print("      3. CamTwist (Mac)")
    
    # æ£€æŸ¥æµ‹è¯•å›¾ç‰‡
    print("\n4. æ£€æŸ¥æµ‹è¯•å›¾ç‰‡:")
    test_images = ["test.jpg", "test1.jpg", "test2.jpg", "car.jpg", "license_plate.jpg", "test_plate.jpg"]
    found_images = []
    
    for test_image in test_images:
        if os.path.exists(test_image):
            file_size = os.path.getsize(test_image) / 1024  # è½¬æ¢ä¸ºKB
            print(f"  âœ“ {test_image}: å­˜åœ¨ ({file_size:.1f} KB)")
            found_images.append(test_image)
        else:
            print(f"  âœ— {test_image}: ä¸å­˜åœ¨")
    
    if found_images:
        print(f"    æ‰¾åˆ° {len(found_images)} ä¸ªæµ‹è¯•å›¾ç‰‡")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å›¾ç‰‡ä¿¡æ¯
        if len(found_images) > 0:
            print("\n    ç¤ºä¾‹å›¾ç‰‡é¢„è§ˆ:")
            for img_file in found_images[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                try:
                    img = cv2.imread(img_file)
                    if img is not None:
                        h, w = img.shape[:2]
                        print(f"      {img_file}: {w}x{h} åƒç´ ")
                except:
                    pass
    else:
        print("    è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•å›¾ç‰‡")
        print("    å»ºè®®åˆ›å»ºä»¥ä¸‹æµ‹è¯•æ–‡ä»¶:")
        print("      test.jpg - ç”¨äºæµ‹è¯•")
        print("      test_plate.jpg - è½¦ç‰Œæµ‹è¯•")
    
    # æ£€æŸ¥æµ‹è¯•è§†é¢‘
    print("\n5. æ£€æŸ¥æµ‹è¯•è§†é¢‘:")
    test_videos = ["test_video.mp4", "test_video.avi", "test_video.mov", "car_video.mp4", "test.mp4", "sample.mp4"]
    found_videos = []
    
    for test_video in test_videos:
        if os.path.exists(test_video):
            file_size = os.path.getsize(test_video) / (1024*1024)  # è½¬æ¢ä¸ºMB
            # å°è¯•æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(test_video)
            if cap.isOpened():
                frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                if frames > 0 and fps > 0:
                    duration = frames / fps
                    print(f"  âœ“ {test_video}: å¯ç”¨ ({frames}å¸§, {fps}fps, {duration:.1f}ç§’, {file_size:.1f} MB)")
                    found_videos.append(test_video)
                else:
                    print(f"  ? {test_video}: å¯ä»¥æ‰“å¼€ä½†æ— æ³•è·å–ä¿¡æ¯")
                cap.release()
            else:
                print(f"  âœ— {test_video}: å­˜åœ¨ä½†æ— æ³•æ‰“å¼€")
        else:
            print(f"  âœ— {test_video}: ä¸å­˜åœ¨")
    
    if found_videos:
        print(f"    æ‰¾åˆ° {len(found_videos)} ä¸ªæµ‹è¯•è§†é¢‘")
    else:
        print("    è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•è§†é¢‘")
        print("    å¯ä»¥å½•åˆ¶æˆ–ä¸‹è½½ä¸€äº›æµ‹è¯•è§†é¢‘")
    
    # æ£€æŸ¥ç³»ç»Ÿé…ç½®
    print("\n6. ç³»ç»Ÿé…ç½®:")
    
    # Pythonç‰ˆæœ¬
    print(f"  Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    
    # æ“ä½œç³»ç»Ÿ
    import platform
    print(f"  æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    
    # å†…å­˜ä¿¡æ¯
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"  å†…å­˜: {memory.total // (1024**3)} GB (å¯ç”¨: {memory.available // (1024**3)} GB)")
    except:
        print("  å†…å­˜ä¿¡æ¯: éœ€è¦å®‰è£…psutilåº“")
    
    # ç£ç›˜ç©ºé—´
    try:
        disk = psutil.disk_usage('.')
        print(f"  ç£ç›˜ç©ºé—´: {disk.free // (1024**3)} GB å¯ç”¨ / {disk.total // (1024**3)} GB æ€»é‡")
    except:
        pass
    
    # æ€§èƒ½æµ‹è¯•
    print("\n7. æ€§èƒ½æµ‹è¯•:")
    
    # OpenCV åŸºæœ¬æ“ä½œæµ‹è¯•
    try:
        import time
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # æµ‹è¯•å›¾åƒå¤„ç†é€Ÿåº¦
        start_time = time.time()
        for _ in range(10):
            gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        cv2_time = (time.time() - start_time) / 10
        print(f"  OpenCVå¤„ç†é€Ÿåº¦: {cv2_time*1000:.1f} ms/å›¾åƒ")
    except:
        print("  OpenCVæµ‹è¯•å¤±è´¥")
    
    # NumPy æµ‹è¯•
    try:
        start_time = time.time()
        for _ in range(100):
            a = np.random.rand(1000, 1000)
            b = np.random.rand(1000, 1000)
            c = np.dot(a, b)
        numpy_time = (time.time() - start_time) / 100
        print(f"  NumPyè®¡ç®—é€Ÿåº¦: {numpy_time*1000:.1f} ms/çŸ©é˜µä¹˜æ³•")
    except:
        print("  NumPyæµ‹è¯•å¤±è´¥")
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    
    # æä¾›å»ºè®®
    if len(available_cameras) == 0:
        print("å»ºè®®:")
        print("  1. è¿æ¥æ‘„åƒå¤´æˆ–ä½¿ç”¨è™šæ‹Ÿæ‘„åƒå¤´è½¯ä»¶")
        print("  2. è¿è¡Œå‘½ä»¤æµ‹è¯•æ‘„åƒå¤´: python main.py --list-cameras")
    
    if len(found_models) == 0:
        print("è­¦å‘Š:")
        print("  æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œç³»ç»Ÿå¯èƒ½æ— æ³•å·¥ä½œ")
        print("  è¯·ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°å½“å‰ç›®å½•:")
        print("  https://github.com/ultralytics/ultralytics")
    
    if len(found_images) == 0:
        print("æç¤º:")
        print("  å¯ä»¥æ”¾ç½®ä¸€äº›æµ‹è¯•å›¾ç‰‡åœ¨å½“å‰ç›®å½•")
        print("  æˆ–ä½¿ç”¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹åŠŸèƒ½")
    
    print("\nç³»ç»Ÿå‡†å¤‡çŠ¶æ€:")
    status_ok = "âœ“" if len(found_models) > 0 else "âœ—"
    print(f"  {status_ok} æ¨¡å‹æ–‡ä»¶: {'å·²å‡†å¤‡' if len(found_models) > 0 else 'æœªå‡†å¤‡'}")
    
    status_ok = "âœ“" if len(available_cameras) > 0 else "âš "
    print(f"  {status_ok} æ‘„åƒå¤´: {f'æ‰¾åˆ° {len(available_cameras)} ä¸ª' if available_cameras else 'æœªæ‰¾åˆ°'}")
    
    status_ok = "âœ“" if len(found_images) > 0 else "âš "
    print(f"  {status_ok} æµ‹è¯•å›¾ç‰‡: {f'æ‰¾åˆ° {len(found_images)} ä¸ª' if found_images else 'æœªæ‰¾åˆ°'}")
    
    print("\nå¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹:")
    if len(found_images) > 0:
        print(f"  python main.py --image {found_images[0]}")
    if len(available_cameras) > 0:
        print(f"  python main.py --camera --camera-index {available_cameras[0]['index']}")
    print("  python main.py  # è¿›å…¥äº¤äº’æ¨¡å¼")
    print("=" * 60)


if __name__ == "__main__":
    main()